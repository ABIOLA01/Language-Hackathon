{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491683f1",
   "metadata": {},
   "source": [
    "# Language Identification Challenge \n",
    "Kaggle Hackathon (Advanced Classification Practical Exam) \n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**Damola Abiola**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Hackathon Overview: South African Language Identification Hackathon 2023\n",
    "\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable\n",
    "tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society. \n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "With such a multilingual populations, it is only obvious that the systems and devices also communicate in multi-languages.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2205222%2F7f34544c1b1f61d1a5949bddacfd84a9%2FSouth_Africa_languages_2011.jpg?generation=1604393669339034&alt=media\" width=80%/>\n",
    "                                                            **Image courtesy of South African Government**\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The south African Government hired me to deploy a dependent model that is capable of determining a text which is in any of South Africa's 11 Official languages and identify which\n",
    "language the text is written.\n",
    "\n",
    "### Data overview\n",
    "The dataset used for this challenge is the NCHLT Text Corpora collected by the South African Department of Arts and Culture & Centre for Text Technology (CTexT, North-West University, South Africa). The training set was improved through additional cleaning done by Praekelt.\n",
    "\n",
    "The data is in the form Language ID, Text. The text is in various states of cleanliness. Some NLP techniques will be necessary to clean up the data.\n",
    "File descriptions\n",
    "\n",
    "- train_set.csv - the training set\n",
    "- test_set.csv - the test set\n",
    "- sample_submission.csv - a sample submission file in the correct format\n",
    "\n",
    "Language IDs\n",
    "\n",
    "- afr - Afrikaans\n",
    "- eng - English\n",
    "- nbl - isiNdebele\n",
    "- nso - Sepedi\n",
    "- sot - Sesotho\n",
    "- ssw - siSwati\n",
    "- tsn - Setswana\n",
    "- tso - Xitsonga\n",
    "- ven - Tshivenda\n",
    "- xho - isiXhosa\n",
    "- zul - isiZulu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c983cc",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Data Engineering</a>\n",
    "\n",
    "<a href=#four>4. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#five>5. Model Training / Testing</a>\n",
    "\n",
    "<a href=#six>6. Model Development / Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations / Conclusions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191028a",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "|  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b0c0437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DOWEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DOWEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data analysis and wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import advertools as adv\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import  log_loss\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Libraries to Save/Restore Models\n",
    "import pickle\n",
    "\n",
    "# Downloads\n",
    "nltk.download(['punkt','stopwords'])\n",
    "%matplotlib inline\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660a9cb",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac2203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "df_train = pd.read_csv(r'C:\\Users\\DOWEN\\Downloads\\Hackathon-Language-Identification-main\\input\\train_set.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(r'C:\\Users\\DOWEN\\Downloads\\Hackathon-Language-Identification-main\\input\\test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a66d4",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "|This phase is important. This will help to understand patterns in the data, pinpoint any outliers and indicate relationships between variables using  descriptive statistics and data visualisations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b1af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view the first 5 rows of the train data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e08c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view the first 5 rows of the test data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68bbbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n",
      "information of TRAIN dataset: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n",
      "informationof TEST dataaet: None\n"
     ]
    }
   ],
   "source": [
    "# view the info for both data set.\n",
    "print(f'information of TRAIN dataset: {df_train.info()}')\n",
    "print(f'informationof TEST dataaet: {df_test.info()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348336a",
   "metadata": {},
   "source": [
    "- The Train dataset has two categorical features while test dataset has only one\n",
    "- We observed no missing values for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6874f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7447b3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef166870",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Further exploratory of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed0121bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6304a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a2280",
   "metadata": {},
   "source": [
    "We observed from above that there `No Missing Values in the Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc741156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of Distributin of each language \n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='lang_id',data=df_train, palette=\"autumn\")\n",
    "plt.title('Count of Lang_Id\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09fcb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xho    3000\n",
       "eng    3000\n",
       "nso    3000\n",
       "ven    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "tso    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The count of observations against lan_id\n",
    "df_train.lang_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475841a",
   "metadata": {},
   "source": [
    "We observed that all language id have same value which shows that data are balanced for each language class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec808f7",
   "metadata": {},
   "source": [
    "Unique Language IDs given to us\n",
    "\n",
    "- afr - Afrikaans\n",
    "- eng - English\n",
    "- nbl - isiNdebele\n",
    "- nso - Sepedi\n",
    "- sot - Sesotho\n",
    "- ssw - siSwati\n",
    "- tsn - Setswana\n",
    "- tso - Xitsonga\n",
    "- ven - Tshivenda\n",
    "- xho - isiXhosa\n",
    "- zul - isiZulu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73076dd1",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data cleaning\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data Cleaning ⚡ |\n",
    "| :--------------------------- |\n",
    "|  clean the dataset, and possibly create new features -using Natural language process . |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c5b11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lang_id', 'text'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_train.copy()\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a1efe",
   "metadata": {},
   "source": [
    "# 4.1 Cleaning the datasets \n",
    "We need to remove the noises in the data sets, such as punctuations and numbers to make the data cleaner. Also, We need to clean the train data first and change the text to lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2cd2a",
   "metadata": {},
   "source": [
    "### Cleaning the Train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57043525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00631c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulunatal department of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqosiseko wenza amalungiselelo kumaziko axh...\n",
       "1     xho  idha iya kuba nobulumko bokubeka umsebenzi nap...\n",
       "2     eng  the province of kwazulunatal department of tra...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data cleaning for train data\n",
    "#removing tags \n",
    "to_remove = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});''<.*?>')\n",
    "#function to remove the tags\n",
    "def cleantags(lang):\n",
    "  cleanlang = re.sub(to_remove, '', lang)\n",
    "  return cleanlang\n",
    "df1['text'] = df1['text'].apply(cleantags)\n",
    "\n",
    "#Remove punctuation\n",
    "def remove_punctuation(lang):\n",
    "  stringpunct = string.punctuation \n",
    "  return ''.join([l for l in lang if l not in stringpunct])\n",
    "df1['text'] = df1['text'].apply(remove_punctuation)\n",
    "\n",
    "#removing newline space\n",
    "def cleantext(text):\n",
    "  text =re.sub(\"\\n\",\" \",text)\n",
    "  text = re.sub(r'\\d+','',text)\n",
    "  text = re.sub(r'[@][©®™]','',text)\n",
    "  return text\n",
    "df1['text'] = df1['text'].apply(cleantext)\n",
    "\n",
    "# Make lower case\n",
    "df1['text'] = df1['text'].str.lower()\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa45856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placing some short words\n",
    "#df1['text'] =df1['text'].str.replace(\".txt\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c800bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing short words from train data\n",
    "#df1['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4985f4a",
   "metadata": {},
   "source": [
    "### Cleaning the test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96a0a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data before being cleaned\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95bf767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#made a copy so not to interfere with the original data\n",
    "df1_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32da13df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mmasepala fa maemo a a kgethegileng a letlelel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  mmasepala fa maemo a a kgethegileng a letlelel...\n",
       "1      2  uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3          tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3      4  kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                       winste op buitelandse valuta"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaning for train data\n",
    "#removing tags\n",
    "to_remove = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});''<.*?>')\n",
    "#function to remove the tags\n",
    "def cleantags(lang):\n",
    "  cleanlang = re.sub(to_remove, '', lang)\n",
    "  return cleanlang\n",
    "df1_test['text'] = df1_test['text'].apply(cleantags)\n",
    "\n",
    "#Remove punctuation\n",
    "import string\n",
    "def remove_punctuation(lang):\n",
    "  stringpunct = string.punctuation\n",
    "  return ''.join([l for l in lang if l not in stringpunct])\n",
    "df1_test['text'] =df1_test['text'].apply(remove_punctuation)\n",
    "\n",
    "#removing newline space\n",
    "def cleantext(text):\n",
    "  text =re.sub(\"\\n\",\" \",text)\n",
    "  text = re.sub(r'\\d+','',text)\n",
    "  text = re.sub(r'[@][©®™]','',text)\n",
    "  return text\n",
    "df1_test['text'] = df1_test['text'].apply(cleantext)\n",
    "\n",
    "# Make lower case\n",
    "print ('Lower case...')\n",
    "df1_test['text'] = df1_test['text'].str.lower()\n",
    "\n",
    "df1_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5092d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placing some short words\n",
    "#df1_test['text'] =df1_test['text'].str.replace(\".txt\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b36aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing short words from train data\n",
    "#df1_test['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c8bad",
   "metadata": {},
   "source": [
    "## Insights from cleaning done above\n",
    "- Some languages had english text on them and even short english words eg `txt`  it would have  made sense to remove some english words from those other non english languages but it proof to be a difficult task  deep learning would help in this situation\n",
    "-  in some languages punctuation matter the words can lose meaning and sotho and pedi can have similar words making predictions more complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1079c09",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, create one or more regression models that are able to accurately predict the Sentiment. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400c932",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c52be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the features and the target\n",
    "x = df1['text']\n",
    "y = df1['lang_id']\n",
    "\n",
    "# two vectoriser to use  which one to chose\n",
    "#cv = CountVectorizer(min_df = 1,max_df = 0.9, ngram_range =(1,3),stop_words ='english')\n",
    "tfidf = TfidfVectorizer(min_df = 1,max_df = 0.9, ngram_range =(1,2),stop_words ='english')\n",
    "X = tfidf .fit_transform(x)\n",
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78b918",
   "metadata": {},
   "source": [
    "# Building Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d03a800",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier, Pool, cv\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RidgeClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9ec16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression'\n",
    "         \n",
    "         #'Nearest Neighbors'#,\n",
    "        'MultinomialNB',\n",
    "        #'SGDClassifier',\n",
    "        'ComplementNB', \n",
    "        'Random Forest', \n",
    "        'Ridge',\n",
    "        'BernoulliNB'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9426ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(C=10,\n",
    "            max_iter= 1000,\n",
    "            multi_class='ovr',\n",
    "            random_state= 220,\n",
    "            solver= 'saga'),\n",
    "    #KNeighborsClassifier(1),\n",
    "    MultinomialNB(alpha = 0.1),\n",
    "    #SGDClassifier(loss='hinge',\n",
    "                    #penalty='l2',\n",
    "                    #alpha=1e-3,\n",
    "                    #random_state=42,\n",
    "                    #max_iter=1000),\n",
    "    ComplementNB(),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    RidgeClassifier(alpha = 0.1),\n",
    "    BernoulliNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc546f4",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "611aaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the sites\n",
    "#def CiteParser(content):\n",
    "    #soup = BeautifulSoup(content)\n",
    "    #print soup\n",
    "    #print \"---> site #: \",len(soup('cite'))\n",
    "    #result = []\n",
    "    #for cite in soup.find_all('cite'):\n",
    "        #if cite.string is not None:\n",
    "            #result.append(cite.string.split('/'))\n",
    "            #print cite\n",
    "    #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9475a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic RegressionMultinomialNB model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, classifiers):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m model...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m---> 10\u001b[0m     run_time \u001b[38;5;241m=\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-q -o clf.fit(X_train, y_train)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... predicting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2367\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2369\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2371\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2372\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1167\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1165\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1167\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[0;32m   1169\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    204\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m--> 206\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:157\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    155\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:524\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    521\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n\u001b[0;32m    522\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n\u001b[1;32m--> 524\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n\u001b[0;32m    545\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[1;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n\u001b[0;32m    350\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred,)\n",
    "    precision = metrics.precision_score(y_train, y_pred,average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred,average=\"weighted\")\n",
    "\n",
    "    f1        = metrics.f1_score(y_train, y_pred,average=\"weighted\")\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test,average=\"weighted\")\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf\n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... ALL models done running ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09191d2",
   "metadata": {},
   "source": [
    "##  Model perfomance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98204aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(results, key=lambda x: x['F1 Train'], reverse=True)\n",
    "\n",
    "# Now 'sorted_results' contains the dictionaries sorted by 'F1 Train' in descending order\n",
    "for result in sorted_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683852d7",
   "metadata": {},
   "source": [
    "`logistic regresion` and `Nearest neighbors` are  extremely overfitting  worse than `Ridge`,`MultinomialNB`,`ComplementNB`,`BernoulliNB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57752e",
   "metadata": {},
   "source": [
    "### hypertuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e554372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'alpha': 0.3}\n",
      "accuracy 0.996969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      1.00       281\n",
      "         eng       1.00      1.00      1.00       297\n",
      "         nbl       0.99      0.99      0.99       327\n",
      "         nso       1.00      0.99      1.00       322\n",
      "         sot       0.99      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       286\n",
      "         tsn       1.00      1.00      1.00       297\n",
      "         tso       1.00      1.00      1.00       253\n",
      "         ven       1.00      1.00      1.00       322\n",
      "         xho       0.99      1.00      1.00       313\n",
      "         zul       1.00      0.98      0.99       295\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.1, 1, 5,0.3,0.5, 10]}\n",
    "grid = GridSearchCV(ComplementNB(), param_grid=param_grid,cv= 5,scoring = 'f1_weighted')\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"Best parameters:\")\n",
    "lr_params = grid.best_params_\n",
    "print(grid.best_params_)\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29273a",
   "metadata": {},
   "source": [
    "Count vectorizer works better but takes too long to fit such large data set  i used tfidf to vectorize to see which model perform best "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335b701",
   "metadata": {},
   "source": [
    "`Ridge`,`MultinomialNB`,`ComplementNB`,`BernoulliNB` have the highest f1 score and accuracy which we need to hypertumes to maximise predictions since most of the models are overfiting the f1 score here is not same score Kaggle is giving me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d61cbe",
   "metadata": {},
   "source": [
    "# First Stacking  of high models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db7fec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2eecfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992727272727273"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1['text']\n",
    "y = df1['lang_id']\n",
    "estimators = [('Multinomialnb', MultinomialNB(alpha = 0.1)),('Multinomial', MultinomialNB(alpha = 0.1))]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator = MultinomialNB(alpha = 0.1) )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv1 = CountVectorizer(ngram_range =(1,5),analyzer = \"char\",min_df =1,max_df=0.9)\n",
    "X = cv1.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a81e2",
   "metadata": {},
   "source": [
    "### Second standing that gave me secong highest score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b8efbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996363636363637"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1['text']\n",
    "y = df1['lang_id']\n",
    "estimators = [('MultinomialNB', MultinomialNB(alpha = 0.1)),('Multinomial', MultinomialNB(alpha = 0.1))]\n",
    "\n",
    "clf1 = StackingClassifier(estimators=estimators, final_estimator = RidgeClassifier(alpha = 0.1) )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv1 = CountVectorizer(ngram_range =(3,7),analyzer = \"char\")\n",
    "X = cv1.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "clf1.fit(X_train, y_train)\n",
    "clf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaacc81",
   "metadata": {},
   "source": [
    "third stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93403a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996363636363637"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1['text']\n",
    "y = df1['lang_id']\n",
    "estimators = [('MultinomialNB', MultinomialNB(alpha = 0.1)),('Multinomial', MultinomialNB(alpha = 0.1))]\n",
    "\n",
    "clf2 = StackingClassifier(estimators=estimators, final_estimator = RidgeClassifier(alpha = 0.01) )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv1 = CountVectorizer(ngram_range =(3,8),analyzer = \"char\")\n",
    "X = cv1.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3bcf5",
   "metadata": {},
   "source": [
    "#  Choosing the best model for FINAL submission file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc43b3",
   "metadata": {},
   "source": [
    "FINAL STACKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fead028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOWEN\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x= df1[\"text\"]\n",
    "y = df1[\"lang_id\"]\n",
    "cv = CountVectorizer(ngram_range=(6,6), analyzer='char', min_df=2, max_df=0.9, stop_words='english')\n",
    "\n",
    "X = cv.fit_transform(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "\n",
    "                                                    test_size=0.01,\n",
    "\n",
    "                                                    random_state=10)\n",
    "x_test = cv.transform(df_test[\"text\"]) #going to use the test data to test the performance of the test and for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c5513",
   "metadata": {},
   "source": [
    "FITTING FIRST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bc50504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "estimators = [('Complement', ComplementNB(alpha = 0.01)),('Multinomial', MultinomialNB(alpha=0.01))]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator = MultinomialNB(alpha = 0.01) , n_jobs=-1,passthrough=True)\n",
    "clf.fit(X_train, y_train)\n",
    "print (clf.score(X_test, y_test))\n",
    "y_pred1 = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d994b4",
   "metadata": {},
   "source": [
    "SECOND MODELS FOR FINAL STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7d6eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "estimators = [('Complement', ComplementNB(alpha = 0.01)),('Multinomial', MultinomialNB(alpha=0.02))]\n",
    "\n",
    "clf2 = StackingClassifier(estimators=estimators, final_estimator = clf, n_jobs=-1,passthrough=True)\n",
    "clf2.fit(X_train, y_train)\n",
    "print(clf2.score(X_test, y_test))\n",
    "y_pred1 = clf2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51879df6",
   "metadata": {},
   "source": [
    "# CONCLUSION \n",
    "MOst of the models are over fitting after stacking locally im getting 1 while on kaggle i get 0.9753 which is 0.0247 less meaning the models are overfitting by a great margin .Some of the languages we not predicted correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9049a",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 7. Model Documentation and Submission file\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model documentation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section it contains submission files and model saving |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e550e2c",
   "metadata": {},
   "source": [
    "general submission file for some models i tried "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76010de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(df_test['index'])\n",
    "test1 = df_test['text'] #using cleaned test text data \n",
    "# vectorise test data\n",
    "test_vec = cv.transform(test1) # replace cv with tfidt if used a different vectorizer\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = clf.predict(test_vec) #replace clf with any model you wanna \n",
    "# Assign a new column of predictions\n",
    "submission_df['lang_id'] = y_pred\n",
    "# save the csv file and submit it. \n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12532619",
   "metadata": {},
   "source": [
    "\n",
    "submission file for final  super stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8313762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(df_test['index'])\n",
    "\n",
    "submission_df['lang_id'] = y_pred1 # predictions generated by stacking \n",
    "\n",
    "submission_df.to_csv('submissionfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1cb8c7",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "## Reference Links\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd9562",
   "metadata": {},
   "source": [
    "Resources that helped me with the challenges\n",
    "- https://www.kaggle.com/datasets/basilb2s/language-detection\n",
    "- edsa buiding classifiers notebook\n",
    "- https://bush-dev.com/introduction-to-stacking-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "04455e36e172f6b292652d16f1e65dd2a7915d80c3850a404294de2c47ba9b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
